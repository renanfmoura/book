\chapter{Lógica Proposicional}
\section{Introdução}

\section{Regras de Inferência}
Quando nos comunicamos, é habitual utilizar diferentes estruturas de linguagem que nos aproximem do sentido que queremos dar a alguma sentença. Na lógica proposicional, esses padrões são também amplamente utilizados e importantes para a construção de fórmulas e serão melhor aprofundados a seguir.
%Sugestões
%Acho que poderíamos juntar a parte de semântica do capítulo 6 
%(na qual ele discute o que é algo ser verdadeiro ou falso e introduz as tabelas verdade) 
%com os capítulos anteriores (caps 2-5), 
%onde ele introduz as regras de inferência, a dedução natural e o Lean. 
%Então introduziríamos as regras, mostrando o seu equivalente na tabela verdade e também no Lean. 
%Depois dessa seção mostraríamos as árvores mais complexas de dedução natural tb dessa forma. 

\subsection{Implicação} 
A implicação é essencial para o condicionamento de sentenças. Se na lingua falada utilizamos a estrutura "Se ... então" para nos referirmos a acontecimentos que dependem de outros, na logica a ideia é muito semelhante.

Retornando aos primeiros problemas do capítulo, relembramos um dos problemas descritos: % lembrar de add os exemplos na introdução %
\begin{center}
\textbf{Se Ana viajar para o Chile, comprará pesos chilenos}

\textbf{Se a família real não tivesse vindo ao Brasil, então o território se desintegraria}
\end{center}

Apesar das duas sentenças terem a mesma estrutura "Se... então", podemos perceber que as duas tem suas diferenças. Em particular, chamamos a segunda proposição de implicação contrafactual, pois ela afirma como o mundo possivelmente seria, caso a realidade fosse diferentes do que ela realmente é. Esse assunto é discutido por filósofos há seculos e Spinoza e Saul Kripke são nomes de destaque nesses estudos. Entretanto, a lógica matemática se debruça mais especialmente na primeira sentença.

Dessa forma, tomando a primeira sentença como objeto de estudo, como podemos valorar essa implicação?
Para começar a analisar a valoração dessa implicação pensemos em A correspondendo o evento "Ana viaja para o Chile" e B ao evento "Ana compra pesos chilenos". Temos, então, dois casos e uma tabela verdade correpondente:

\begin{center}

Caso 1: Ana viaja para o Chile 

Caso 2: Ana não viaja para o Chile

\end{center}

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline

\textbf{A} & \textbf{B} & \textbf{A $\to$ B} \\ \hline
V          & V          & V                  \\ \hline
V          & F          & F                  \\ \hline
F          & V          & V                  \\ \hline
F          & F          & V                  \\ \hline

\end{tabular}
\end{table}

No primeiro caso, Ana viaja para o Chile e A é verdadeiro. Dessa forma, para a implicação ser verdadeira, B precisa ver também verdadeiro.

No segundo caso, Ana não viaja para o Chile e A é falso.
Dessa forma, nada podemos dizer sobre o evento B e qualquer valor atribuído a ele torna a implicação verdadeira. A esse tipo de afirmação, chamamos de \textbf{verdadeira por vacuidade}.\\

Vamos agora analisar a implicação contrária:
\begin{center}

\textbf{Se Ana comprar pesos chilenos, viajará para o Chile}

\end{center}
Ainda analisando o evento A como "Ana viaja para o Chile" e B como "Ana compra pesos chilenos", temos a seguinte tabela verdade:

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline

\textbf{B} & \textbf{A} & \textbf{B $\to$ A} \\ \hline
V          & V          & V                  \\ \hline
V          & F          & F                  \\ \hline
F          & V          & V                  \\ \hline
F          & F          & V                  \\ \hline

\end{tabular}
\end{table}

A partir da comparação das duas tabelas podemos perceber que a segunda e terceira linhas evidenciam que, apesar de A e B terem o mesmo valor nas duas tabelas, a implicação tem uma valoração diferente. Ou seja, A $\to$ B $\neq$ B $\to$ A. Esse resultado condiz com a nossa intuição pois uma vez que embora saibamos que se Ana viaja para o Chile, comprará pesos chilenos, uma vez que Ana comprou pesos chilenos, não podemos afirmar com certeza que ela viajará para o Chile. Quem sabe Ana seja uma colecionadora de moedas internacionais?\\

Além disso, a implicação é protagonista da regra chamada "regra da exclusão da implicação" ou \textit{Modus Ponens}("A maneira que afirma afirmando" ), ou seja:

\begin{center}

Se Ana viajar para o Chile, comprará pesos chilenos

Ana viajou para o Chile

Ana comprou pesos chilenos

\end{center}

Escrito em dedução natural como:

\begin{prooftree}
    \AxiomC{$A \rightarrow B$}
    \AxiomC{A}
    \BinaryInfC{B}
\end{prooftree}

E com seu correspondente no Lean, sendo:

\vspace{5mm}
\begin{lstlisting} 

section
variable h1 : A → B
variable h2 : A

example : B := h1 h2
end

\end{lstlisting}
\vspace{5mm}

Por outro lado, existe também a "regra de inclusão da implicação". Uma vez que temos uma variável A e conseguimos derivar uma variável B, dizemos que \textbf{A implica em B}. E utilizamos em nossas árvores de dedução natural de tal forma:

\begin{prooftree}
    \AxiomC{$A$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$B$}
    \UnaryInfC{$A \rightarrow B$}
\end{prooftree}

Enquanto no Lean:

\vspace{5mm}
\begin{lstlisting} 

example : A → B :=
assume h : A,
show B, from sorry

\end{lstlisting}
\vspace{5mm}

\subsection{Se e somente se}

Já vimos anteriormente que $A \rightarrow B \neq B \rightarrow A$. Entretanto, em muitos casos na Matemática conseguimos chegar na igualdade dessas duas implicações e precisamos expressar a estrutura da linguagem falada "Se, e somente se". Dessa forma, faz-se uso do símbolo chamado de "bi-implicação" e representado por $\iff$ \\
Poderíamos também utilizar a formalização $A \rightarrow B \land B \rightarrow A$, mas por questões ligadas a praticidade da abreviação, é preferível o uso do novo símbolo apresentado.\\
Para entender melhor a interpretação dessa regra, usaremos o exemplo abaixo:

\begin{center}
    \textbf{Ana viajará para o Chile se, e somente se, comprar pesos chilenos}
\end{center}

Novamente construiremos a bi-implicação tratando o evento A como sendo "Ana viaja ao Chile" e B "Ana compra pesos chilenos". A tabela verdade então será:

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline

\textbf{A} & \textbf{B} & \textbf{A $\iff$ B} \\ \hline
V          & V          & V                  \\ \hline
V          & F          & F                  \\ \hline
F          & V          & F                  \\ \hline
F          & F          & V                  \\ \hline

\end{tabular}
\end{table}

Para melhor visualização dos resultados, vamos também mostrar uma tabela verdade que utiliza a definição da bi-implicação com o "e":

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline

\textbf{A} & \textbf{B} & \textbf{A $\iff$ B}& \textbf{B $\iff$ A} & \textbf{(B $\iff$ A) $\land$ (A $\iff$ B)} \\ \hline
V          & V          & V                  & V                   & V\\ \hline
V          & F          & F                  & V                   & F\\ \hline
F          & V          & F                  & V                   & F\\ \hline
F          & F          & V                  & V                   & V\\ \hline

\end{tabular}
\end{table}

Dessa forma, temos os casos:
\begin{center}

Caso 1: Ana viaja para o Chile 

Caso 2: Ana não viaja para o Chile

Caso 3: Ana compra pesos chilenos

Caso 4: Ana não compra pesos chilenos

\end{center}
Assim, com essa sentença sabemos que o caso 1 acontece se, e somente se o caso 3 acontece, e o caso 2 acontece se, e somente se o caso 4 também acontece.\\
Em dedução natural a regra da inclusão bi-implicação evidencia a necessidade de possuirmos duas implicações verdadeiras. Escrevemos a regra como:

\begin{prooftree}
    \AxiomC{$A$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$B$}
    \AxiomC{$B$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$A$}
    \BinaryInfC{$A \iff B$}
\end{prooftree}

No lean, temos o comando "iff.intro" que introduz o símbolo dado a verdade das duas implicações:
\vspace{5mm}
\begin{lstlisting} 

example : A ↔ B :=
iff.intro
  (assume h : A,
    show B, from sorry)
  (assume h : B,
    show A, from sorry)

\end{lstlisting}
\vspace{5mm}

Enquanto para a exclusão, a regra em dedução natural é muito semelhante a regra da exclusão da implicação:

\begin{prooftree}
    \AxiomC{$A \iff B$}
    \AxiomC{$A$}
    \BinaryInfC{$B$}
\end{prooftree}
\begin{prooftree}
    \AxiomC{$A \iff B$}
    \AxiomC{$B$}
    \BinaryInfC{$A$}
\end{prooftree}

E seu correspondente no lean é feito pelos comandos de eliminação a direita e a esquerda:

\vspace{5mm}
\begin{lstlisting} 

section
  variable h1 : A ↔ B
  variable h2 : A

  example : B := iff.elim_left h1 h2
end

section
  variable h1 : A ↔ B
  variable h2 : B

  example : A := iff.elim_right h1 h2
end

\end{lstlisting}
\vspace{5mm}


\subsection{Conjunção}
A regra da conjunção se refere ao uso ``e'' na linguagem informal, de forma que juntamos duas informações. Podemos ter frases como:
\begin{center}
\textbf{Santiago é a capital do Chile e o deserto do Atacama está localizado no Chile.}
\end{center}

Ao mesmo tempo, podemos utilizar o ``e'' para conectar duas informações que nem mesmo possuem relação entre si. Por exemplo, podemos dizer que:
\begin{center}
\textbf{Santiago é a capital do Chile e Bolsonaro é o presidente do Brasil.}
\end{center}
Quando utilizamos o ``e'', representado pelo símbolo $\land$ na lógica, o que de fato importa é estarmos unindo duas informações que são verdadeiras. Isso fica claro na tabela verdade abaixo, na qual é possível ver que quando $A$ ou quando $B$ são falsos, $A\land B$ é falso:

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{A} & \textbf{B} & \textbf{A $\land$ B} \\ \hline
V          & V          & V                  \\ \hline
V          & F          & F                  \\ \hline
F          & V          & F                  \\ \hline
F          & F          & F                  \\ \hline
\end{tabular}
\end{table}

Dessa forma, na dedução natural, podemos introduzir um ``e'', quando temos $A$ e também temos $B$. Assim, se $A$ e $B$ forem verdadeiros, $A \land B$ também vai ser. 

 \begin{prooftree}
     \AxiomC{A}
     \AxiomC{B}
     \BinaryInfC{$A \land B$}
\end{prooftree}

No Lean, representamos essa operação pela função $and.intro$, conforme o exemplo abaixo:
\vspace{5mm}
\begin{lstlisting} 
variables A B : Prop

example (h1 : A) (h2 : B) : A ∧ B :=
and.intro h1 h2
\end{lstlisting}
\vspace{5mm}

Seguindo esse raciocínio, é possível observar que sempre que temos $A \land B$, teremos $A$ e $B$ separadamente. Essa é a operação chamada de exclusão do ``e''.

Para excluir o $B$ de, por exemplo, $A \land B$, temos a chamada exclusão pela esquerda, conforme descrita abaixo:

 \begin{prooftree}
     \AxiomC{$A \land B$}
     \UnaryInfC{A}
\end{prooftree}

No Lean, essa operação pode ser feita utilizando a função $and.left$, conforme o código a seguir: 
\vspace{5mm}
\begin{lstlisting} 
variables A B : Prop

example (h1 : A ∧ B): A :=
and.left h1
\end{lstlisting}
\vspace{5mm}

Alternativamente, é possível realizar a mesma operação da seguinte forma:
\vspace{5mm}
\begin{lstlisting} 
variables A B : Prop

example (h1 : A ∧ B): A :=
h1.left
\end{lstlisting}
\vspace{5mm}
Para excluir o $A$, temos a chamada exclusão pela direita:

 \begin{prooftree}
     \AxiomC{$A \land B$}
     \UnaryInfC{B}
\end{prooftree}

No Lean, essa operação é realizada utilizando a função $and.right$, de maneira semelhante ao que foi descrito anteriormente para o $and.left$. 

\subsection{Disjunção}

A regra da disjunção se refere ao uso do ``ou''. Na linguagem informal, podemos utilizá-lo para expressar situações excludentes, como da seguinte forma:
\begin{center}
\textbf{Alexandre vai viajar para o Atacama ou Alexandre vai viajar para Santiago.}\\
\end{center}
Nesse caso, é possível que uma pessoa compreenda que somente uma das duas situações vai ocorrer, ou seja, que Alexandre somente vai para um dos dois lugares no Chile. Contudo, quando utilizamos o  ``ou'' na lógica, representado pelo símbolo $\lor$, também estamos levando em consideração situações nas quais ambas as proposições são verdadeiras. Dessa forma, conforme indicado na tabela verdade a seguir, a sentença formada pelo ``ou'' será verdadeira quando somente $A$ for verdadeiro, quando somente $B$ for verdadeiro ou quando ambos forem verdadeiros. 

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{A} & \textbf{B} & \textbf{A $\lor$ B} \\ \hline
V          & V          & V                 \\ \hline
V          & F          & V                 \\ \hline
F          & V          & V                 \\ \hline
F          & F          & F                 \\ \hline
\end{tabular}
\end{table}

Não só o ``ou'' formará uma sentença verdadeira quando uma ou ambas as situações forem verdadeiras, como também quando ambas as situações forem verdadeiras, mas não possuírem nenhuma relação entre si. Por exemplo, a seguinte sentença é verdadeira: 
\begin{center}
\textbf{Santiago é a capital do Chile ou Bolsonaro é o presidente do Brasil.}\\
\end{center}

É verdadeiro que Santiago é a capital do Chile e que Bolsonaro é o presidente do Brasil. Logo, toda a sentença é verdadeira, apesar de não soar de forma natural na linguagem informal.

Na dedução natural, como o ``ou'' é verdadeiro mesmo que somente um de seus elementos seja verdadeiro, introduzimos o $\lor$ tendo somente $A$ ou somente $B$. Logo, pode-se formar $A \lor B$ da seguinte forma:
\begin{prooftree}
     \AxiomC{A}
     \UnaryInfC{$A \lor B$}
\end{prooftree}

%adicionar explicacao de como o lean entende que o B ficara do lado direito do ou

No Lean, essa operação de introdução do ``ou'' é realizada utilizando a função $or.inl$. Essa função indica que queremos adicionar o $A$ do lado esquerdo do $\lor$ (por isso, ``or include left''). Dessa forma, teremos o seguinte código: 
\begin{lstlisting} 
variables A B : Prop

example (h1 : A): A ∨ B :=
or.inl h1
\end{lstlisting} 

Alternativamente, é possível realizar a introdução do $\lor$ a partir do $B$:
\begin{prooftree}
     \AxiomC{B}
     \UnaryInfC{$A \lor B$}
\end{prooftree}

Nesse caso, como o $B$ está sendo adicionado à direita do $\lor$ utilizamos a função $or.inr$ no Lean (ou seja,  ``or include right''). 

\begin{lstlisting} 
variables A B : Prop

example (h1 : B): A ∨ B :=
or.inr h1
\end{lstlisting} 

Para excluir o ``ou'' de $A \lor B$ é preciso estruturar uma árvore de dedução natural de forma que $A$ e $B$ resultem em um mesmo resultado $C$. Chegando nesse $C$, é possível substituir o $A \lor B$ pelo C. A seguinte árvore de dedução natural demonstra essa estrutura:

\begin{prooftree}
    \AxiomC{$A \lor B$}
    \AxiomC{$A$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$C$}
    \AxiomC{$B$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$C$}
    \TrinaryInfC{$C$}
\end{prooftree}
     
No Lean, para excluir o ``ou'', utiliza-se a função $or.elim$. Ao lado do $or.elim$ é necessário inserir a hipótese contendo o ``ou'',  que deseja-se eliminar. Em seguida, deve-se abrir dois parênteses. Esses dois parênteses serão equivalentes às duas colunas contendo, respectivamente, $A$ e $B$ na árvore de dedução natural acima. Dessa forma, um parênteses começa com o $assume$ de $A$ e o outro com o$assume$ de $B$. O objetivo é que a partir deles chegue-se à hipótese C.  O código abaixo mostra a estrutura de como ficaria uma operação de eliminação do ``ou''(o ``sorry'' nas provas abaixo representa a etapa em que se prova que a partir de $A$ é possível chegar em $C$) :

\begin{lstlisting}
variables A B C D : Prop

example (h1: A ∨ B): C :=
or.elim h1
(assume h2: A, sorry)
(assume h2: B, sorry)
\end{lstlisting}

Como exemplo mais concreto, sem o uso do ``sorry'', é possível observar a prova abaixo, na qual utiliza-se as hipóteses $A \rightarrow C$ e $B \rightarrow C$ para se chegar à C a partir de $A$ e $B$:

\begin{lstlisting} 
variables A B C D : Prop

example (h1 : A → C) (h2 : B → C) (h3: A ∨ B): C :=
or.elim h3
(assume h4: A,
show C, from h1 h4)
(assume h4: B, 
show C, from h2 h4)
\end{lstlisting} 


\subsection{Negação}
%Incluir um exemplo de algum "quebra-cabeça"
A negação de $A$ é  representada  em  símbolos por $\neg A $. 
Mostrar que $\neg A $ ocorre, em termos lógicos, é o mesmo que mostrar que $A $ leva a uma contradição. Em dedução natural, temos uma prova que tem a seguinte árvore, na qual $\bot$ é o símbolo para falso, contradição ou absurdo:
\begin{prooftree}
    \AxiomC{A}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$\bot$}
    \UnaryInfC{$\neg A$}
\end{prooftree}

Esta é uma outra forma de raciocínio hipotético, similar a utilizada em "se ... então" . Começamos supondo $A$. Em seguida, continuamos a prova aplicando as regras  já apresentadas, representadas pelos três pontinhos na árvore de dedução natural, até chegarmos a uma contradição.

A pergunta a se fazer em seguida é: de que forma uma contradição aparece numa prova, ou seja, como a encontramos? Suponha, por exemplo, que ao construir uma prova temos uma hipótese $A$ que nos leva a concluir que uma outra hipotése $B$ ocorre ao mesmo tempo que $\neg B$ também ocorre, no entanto se temos $B$ e  $ \neg B $, então temos uma contradição.
Em dedução natural, representamos essa ideia por:

\begin{prooftree}
    \AxiomC{$\neg B$}
    \AxiomC{B}
    \BinaryInfC{$\bot$}
\end{prooftree}

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{A} & \textbf{$\neg A$}  \\ \hline
V          & F                            \\ \hline
F          & V                            \\ \hline
\end{tabular}
\end{table}

A tabela verdade reforça o fato de que é ímpossível que uma proposição e sua negação sejam ambas verdadeiras ao mesmo tempo.

Ao utilizarmos o Lean, as regras de inferência de eliminação e introdução da negação podem ser obtidas atráves dos comandos a seguir: 

\begin{lstlisting} 
variables p q : Prop
-- show false, from ...

example (h1 : P → Q) (h2 : ¬Q) : ¬P :=
assume hp : P,
    show false, from h2 (h1 hp)
\end{lstlisting} 

Note que a hipotése que contém a negação vem primeiro após o \verb|from| e \textit{Q} é resultado do uso da regra de eliminação da implicação, além disso o símbolo $\neg Q$ é escrito como \verb| \not Q|. Na biblioteca padrão do Lean, $ \neg P$ é na verdade uma abreviação de $ P \rightarrow false $, ou seja, o fato de que $P$ implica uma contradição.

Uma vez apresentado o símbolo para \textit{falso}, a seguir apresentamos o símbolo para \textit{verdadeiro}. No entanto,  \textit{verdadeiro} ou \textit{true} não possui regra de eliminação, apenas a regra de introdução:

\begin{prooftree}
    \AxiomC{}
    \UnaryInfC{$\top $}
\end{prooftree}

%Citar mais alguma info sobre o símbolo true?
\section{Exemplos adicionais de Dedução Natural}

Nesta seção serão apresentados exemplos adicionais de provas de dedução natural e seus equivalentes no Lean. Também será explicado como construir essas árvores do zero, partindo somente do  que se quer provar.  
\begin{itemize}

\item Prova de A $\rightarrow$ C a partir de A $\rightarrow$ B e B $\rightarrow$ C

\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
                               \AxiomC{$A \rightarrow B$}
                   \BinaryInfC{B}
                                        \AxiomC{$B \rightarrow C$}
                                 \BinaryInfC{C}
                                 \RightLabel{\scriptsize(1)}
                                 \UnaryInfC{$A \rightarrow C$}
\end{prooftree}

Como construir essa prova? Primeiro, começamos pelo que se quer provar: $A \rightarrow C$. Podemos escrever isso na última linha, já que é onde queremos chegar. Como a prova é de uma implicação, sabemos que na linha logo acima dessa vamos chegar no $C$:
\begin{prooftree}
\AxiomC{C}
\UnaryInfC{$A \rightarrow C $}
\end{prooftree}

Agora podemos considerar as hipóteses. Como a prova é de $A\rightarrow B$, vamos utilizar o $A$ em algum momento na árvore. Além disso, pelo enunciado, sabemos que vamos também utilizar o  $A \rightarrow B$ e $B \rightarrow C$. Então teremos uma estrutura razoavelmente parecida com essa: 

\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
        \noLine
        \UnaryInfC{$\vdots$}
    \AxiomC{$A \rightarrow B$}
        \noLine
        \UnaryInfC{$\vdots$}
    \AxiomC{$B \rightarrow C$}
        \noLine
        \UnaryInfC{$\vdots$}
    \TrinaryInfC{$C$}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \rightarrow C $}
\end{prooftree}
     
A partir disso, é possível observar com mais facilidade quais regras de dedução natural podem ser aplicadas ao problema. No caso, observamos que temos $A$ e $A\rightarrow B$. Logo, é possível obter $B$. 

\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
    \AxiomC{$A \rightarrow B$}
    \BinaryInfC{$B$}
    \AxiomC{$B \rightarrow C$}
        \noLine
        \UnaryInfC{$\vdots$}
    \BinaryInfC{$C$}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \rightarrow C $}
\end{prooftree}
     
Por fim, obtemos $C$ a partir de $B$ e de $B \rightarrow C$, formando a ávore apresentada de início. 

No Lean, essa prova poderia ser feita da seguinte forma: 
\begin{lstlisting}
variables A B C: Prop
example (h1: A → B) (h2: B → C): A → C :=
assume h3: A,
have h4: B, from h1 h3,
h2 h4
\end{lstlisting}

A prova acima também pode ser intuitivamente pensada como (A $\rightarrow$ B) $\land$ (B $\rightarrow$ C) $\rightarrow$ (A $\rightarrow$ C). Nesse caso, teria-se a seguinte árvore:

\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
               \AxiomC{}
               \RightLabel{\scriptsize(2)}
               \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C)$}
               \UnaryInfC{$A \rightarrow B$}
        \BinaryInfC{B}
                                           \AxiomC{}
                                           \RightLabel{\scriptsize(2)}
                                           \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C)$}
                                           \UnaryInfC{$B \rightarrow C$}
                          \BinaryInfC{$C$}
                          \RightLabel{\scriptsize(1)}
                          \UnaryInfC{$A \rightarrow C$}
                          \RightLabel{\scriptsize(2)}
                          \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C) \rightarrow (A \rightarrow C)$}
\end{prooftree}

Nesse caso, seria possível construir a árvore da seguinte forma: primeiro, começamos pelo que se quer provar ($(A \rightarrow B) \land (B \rightarrow C) \rightarrow (A \rightarrow C)$). Como vamos chegar em $A \rightarrow C$, podemos colocá-lo logo acima do que queremos provar. Ainda assim, continuamos com uma implicação, então podemos inserir o $C$ antes do $A \rightarrow C$. 

Como hipótese, teremos o o $A$ (de $A \rightarrow C$) e o $(A \rightarrow B) \land (B \rightarrow C)$ (vindo do resultado final: $(A \rightarrow B) \land (B \rightarrow C) \rightarrow (A \rightarrow C)$). Assim, teremos uma estrutura dessa forma: 
\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
        \noLine
        \UnaryInfC{$\vdots$}
    \AxiomC{}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C)$}
        \noLine
        \UnaryInfC{$\vdots$}
    \BinaryInfC{$C$}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \rightarrow C$}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C) \rightarrow (A \rightarrow C)$}
\end{prooftree}
     
Como sabemos que queremos chegar em um $C$, podemos utilizar o $B \rightarrow C$ para isso ($B \rightarrow C$ pode ser obtido a partir da operação de exclusão do $\land$ na hipótese de número 2) . Contudo, é necessário ter $B$ para realizar essa operação. O $B$ pode ser obtido a partir do $A$ e do $A \rightarrow B$. Logo, é possível construir a árvore. 

No Lean essa prova poderia ser feita da seguinte forma: 
\begin{lstlisting}
variables A B C: Prop
example: ((A → B) ∧ (B → C)) → (A → C) :=
assume h1: (A → B) ∧ (B → C),
assume h2: A,
have h3: B, from (and.left h1) h2,
(and.right h1) h3
\end{lstlisting}

Nos dois casos acima, podemos observar , nas árvores de dedução natural, a utilização de números em determinadas hipóteses. Utilizamos esses para evidenciar onde descartamos as hipóteses marcadas. 

\item Prova de $Q\land S$ a partir de $(P\land Q)\land R$ e $S \land T$

\begin{prooftree}
    \AxiomC{$(P \land Q) \land S$}
    \UnaryInfC{$P \land Q$}
    \UnaryInfC{Q}
                                      \AxiomC{$S \land T$}
                                      \UnaryInfC{S}
                      \BinaryInfC{$Q \land S$}
\end{prooftree}
Nesse caso, não descartamos nenhuma hipótese pois assumimos $(P\land Q)\land R$ e $S \land T$ como verdade e apenas derivamos a prova.

Para construir essa prova, partimos também de onde queremos chegar: $Q \land S$. Para formar um $\land$, precisamos de $Q$ e de $S$ separadamente. Logo, podemos escrevê-los acima do $Q \land S$. Pelo enunciado, sabemos que vamos usar como hipótese: $(P\land Q)\land R$ e $S \land T$. Assim, teremos a seguinte estrutura: 

\begin{prooftree}
    \AxiomC{$(P \land Q) \land S$}
     \noLine
    \UnaryInfC{$\vdots$}
     \noLine
    \UnaryInfC{$Q$}
    \AxiomC{$S \land T$}
     \noLine
    \UnaryInfC{$\vdots$}
     \noLine
    \UnaryInfC{S}
    \BinaryInfC{$Q \land S$}
\end{prooftree}

É possível obter o $S$ a partir de qualquer uma das hipóteses. O $Q$ só é possível obter a partir de $(P \land Q) \land S$. Logo, a partir de uma série de operações de exclusão do $\land$, constrói-se a parte restante da prova. 

No Lean, essa prova poderia ser feita da seguinte forma: 

\begin{lstlisting}
variables P Q R S T: Prop
example (h1: (P ∧ Q) ∧ R) (h2: S ∧ T): Q ∧ S :=
have h3: Q, from and.right (and.left h1),
have h4: S, from and.left h2,
and.intro h3 h4
\end{lstlisting}

\item Prova de $(A \rightarrow (B \rightarrow C)) \rightarrow (A \land B \rightarrow C)$ :
\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$A \rightarrow (B \rightarrow C)$}
                                               \AxiomC{}
                                               \RightLabel{\scriptsize(1)}
                                               \UnaryInfC{$A \land B$}
                                               \UnaryInfC{A}
                        \BinaryInfC{$B \rightarrow C$}
                                                                          \AxiomC{}
                                                                          \RightLabel{\scriptsize(1)}
                                                                          \UnaryInfC{$A \land B$}
                                                                          \UnaryInfC{B}
                                                      \BinaryInfC{C}
                                                      \RightLabel{\scriptsize(1)}
                                                      \UnaryInfC{$A \land B \rightarrow C$}
                                                      \RightLabel{\scriptsize(2)}
                                                      \UnaryInfC{$(A \rightarrow (B \rightarrow C)) \rightarrow (A \land B \rightarrow C) $}
\end{prooftree}

%essa prova é bem parecida com as outras, preciso explicar?

\item Prova de $A \land B \iff B \land A$:
\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \land B$}
    \UnaryInfC{B}
                              \AxiomC{}
                              \RightLabel{\scriptsize(1)}
                              \UnaryInfC{$A\land B$}
                              \UnaryInfC{A}
             \BinaryInfC{$B \land A$}
                                                         \AxiomC{}
                                                         \RightLabel{\scriptsize(2)}
                                                         \UnaryInfC{$B \land A $}
                                                         \UnaryInfC{A}
                                                                                    \AxiomC{}
                                                                                    \RightLabel{\scriptsize(2)}
                                                                                    \UnaryInfC{$B \land A$}
                                                                                    \UnaryInfC{B}
                                                                     \BinaryInfC{$A \land B$}
                                                                     \RightLabel{\scriptsize(1,2)}
                                      \BinaryInfC{$A \land B \iff B \land A$}
\end{prooftree}

Para construir essa prova, partimos do $A \land B \iff B \land A$ ao final da prova. Para obtê-lo, precisamos partir de $B \land A$ e chegar no $A \land B$ e também partir de  $A \land B$ e chegar em $B \land A$. Sabendo que chegaremos nos dois, podemos escrevê-los na linha acima de  $A \land B \iff B \land A$. Sabendo que partiremos também dos dois, podemos escrevê-los como hipóteses. Teremos uma estrutura como essa: 
\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \land B$}
     \noLine
    \UnaryInfC{$\vdots$}
     \noLine
    \UnaryInfC{$B \land A$}
    \AxiomC{}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$B \land A$}
     \noLine
    \UnaryInfC{$\vdots$}
     \noLine
    \UnaryInfC{$A \land B$}
    \RightLabel{\scriptsize(1,2)}
    \BinaryInfC{$A \land B \iff B \land A$}
\end{prooftree}

Para formar $A \land B$ e $B \land A$ precisamos de $A$ e $B$ separadamente. Estes podem ser obtidos a partir das hipóteses. Logo, repetindo as hipóteses e realizando a exclusão do $\land$, formamos a árvore final.

No Lean, essa prova poderia ser construída da seguinte forma:
\begin{lstlisting}
variables A B C: Prop
example: A ∧ B ↔ B ∧ A :=
iff.intro 
    (assume h1: A ∧ B,
    and.intro (and.right h1) (and.left h1))
    (assume h3: B ∧ A,
    and.intro (and.right h3) (and.left h3))

\end{lstlisting}

\item Prova de $A \land (B \lor C) \rightarrow (A \land B) \lor (A \land C)$

\begin{prooftree}

\AxiomC{}                   
\RightLabel{\scriptsize(2)} 
\UnaryInfC{$A \land (B \lor C)$}                
\UnaryInfC{$B \lor C$}

\AxiomC{}
\RightLabel{\scriptsize(2)} 
\UnaryInfC{$A \land (B \lor C)$}
\UnaryInfC{A}
\AxiomC{}
\RightLabel{\scriptsize(1)} 
\UnaryInfC{B}
\BinaryInfC{$A \land B$}
\UnaryInfC{$(A \land B) \lor (A \land C)$}

\AxiomC{}
\RightLabel{\scriptsize(2)} 
\UnaryInfC{$A \land (B \lor C)$}
\UnaryInfC{A}
\AxiomC{}
\RightLabel{\scriptsize(1)} 
\UnaryInfC{C}
\BinaryInfC{$A \land C$}
\UnaryInfC{$(A \land B ) \lor (A \land C)$}

            \RightLabel{\scriptsize(1)} 
            \TrinaryInfC{$ (A \land B) \lor (A \land C)$}
            \RightLabel{\scriptsize(2)} 
           \UnaryInfC{$A \land (B \lor C) \rightarrow (A \land B) \lor (A \land C)$}
\end{prooftree}

Para escrever essa prova, podemos partir, como nas outras, do objetivo final: $A \land (B \lor C) \rightarrow (A \land B) \lor (A \land C)$. Como estamos provando uma implicação, vamos chegar em $(A \land B) \lor (A \land C)$ na linha anterior. Observamos também que $A \land (B \lor C)$ será uma hipótese. Teremos, então, uma estrutura como essa:

\begin{prooftree}
 \AxiomC{}
\RightLabel{\scriptsize(2)} 
\UnaryInfC{$A \land (B \lor C)$}
     \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$(A \land B) \lor (A \land C)$}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$A \land (B \lor C) \rightarrow (A \land B) \lor (A \land C)$}
\end{prooftree}

Como proceder a partir dessa estrutura? Para formar o $(A \land B) \lor (A \land C)$ será necessário o $A \land B$ isoladamente ou o $A \land C$ (a partir de qualquer um dos dois é possível realizar a introdução do $\lor$ e assim chegar em $(A \land B) \lor (A \land C)$). Independente de qual dos dois serão utilizados, nota-se que, para formar o ``e'', será necessário: o $A$ e também o $B$ ou o $C$. O $A$ pode ser facilmente obtido  a partir da hipótese. Para obter $B$ ou $C$ isoladamente, será necessário realizar a exclusão do $B \lor C$ contido no ``e'' da hipótese. Nota-se que para realizar a exclusão do ``ou'', é necessário levantar $B$ e $C$ como hipótese. Assim, podemos formar tanto $A \land B$, quanto $A \land C$. Assim, é possível chegar no resultado final descrito acima. 

No Lean, essa prova poderia ser construída da seguinte forma:
\begin{lstlisting}
variables A B C: Prop
example: (A ∧ (B ∨ C)) → ((A ∧ B) ∨ (A ∧ C)) :=
assume h1: A ∧ (B ∨ C),
have h2: B ∨ C, from and.right h1,
have h4: A, from and.left h1,
or.elim h2
    (assume h3: B, 
    or.inl (and.intro h4 h3))
    (assume h3: C,
    or.inr (and.intro h4 h3))
\end{lstlisting}

\item Prova do PHP-3
    O princípio da casa dos pombos afirma que  se n pombos devem ser postos em m casas, e se n > m, então pelo menos uma casa irá conter mais de um pombo. Apesar desse princípio  generalizado ser muito amplo para ser provado por árvores dedutivas, conseguimos provar o caso de 3 pombos e 2 casas de pombo utilizando árvores dedutivas.
    %tentaremos por a árvore?%

No Lean, essa prova poderia ser construída da seguinte forma: 
\begin{lstlisting}
variables P11 P12 P21 P22 P31 P32 : Prop

example: ((P11 ∨ P12) ∧ (P21 ∨ P22)) ∧ (P31 ∨ P32) → (P22 ∧ P32) ∨ ((P11 ∧ P31) ∨ ((P12 ∧ P22) ∨ ((P11 ∧ P21) ∨ ((P12 ∧ P32) ∨ (P21 ∧ P31))))) :=

assume h: ((P11 ∨ P12) ∧ (P21 ∨ P22)) ∧ (P31 ∨ P32),
have ha: P11 ∨ P12, from and.left (and.left h),
or.elim ha
    (assume h1: P11, 
        have hb: P21 ∨ P22, from and.right (and.left h),
            or.elim hb
                (assume h2: P21, or.inr (or.inr (or.inr (or.inl (and.intro h1 h2)))))
                (assume h2: P22, 
                    have hc: P31 ∨ P32, from and.right h,
                        or.elim hc
                            (assume h3: P31, or.inr (or.inl (and.intro h1 h3)))
                            (assume h3: P32, or.inl (and.intro h2 h3))))
    (assume h1: P12, 
        have hb: P21 ∨ P22, from and.right (and.left h),
            or.elim hb
                (assume h2: P21, 
                    have hc: P31 ∨ P32, from and.right h,
                        or.elim hc
                            (assume h3: P31, or.inr (or.inr (or.inr (or.inr (or.inr (and.intro h2 h3))))))
                            (assume h3: P32, or.inr (or.inr (or.inr (or.inr (or.inl (and.intro h1 h3)))))))
                (assume h2: P22, or.inr (or.inr (or.inl (and.intro h1 h2)))))
\end{lstlisting}

\end{itemize}

\section{Exercícios}
