\chapter{Lógica Proposicional}
\section{Introdução}

\section{Regras de Inferência}
Quando nos comunicamos, é habitual utilizar diferentes estruturas de linguagem que nos aproximem do sentido que queremos dar a alguma sentença. Na lógica proposicional, esses padrões são também amplamente utilizados e importantes para a construção de fórmulas e serão melhor aprofundados a seguir.
%Sugestões
%Acho que poderíamos juntar a parte de semântica do capítulo 6 
%(na qual ele discute o que é algo ser verdadeiro ou falso e introduz as tabelas verdade) 
%com os capítulos anteriores (caps 2-5), 
%onde ele introduz as regras de inferência, a dedução natural e o Lean. 
%Então introduziríamos as regras, mostrando o seu equivalente na tabela verdade e também no Lean. 
%Depois dessa seção mostraríamos as árvores mais complexas de dedução natural tb dessa forma. 

\subsection{Implicação} 
A implicação é essencial para o condicionamento de sentenças. Se na lingua falada utilizamos a estrutura "Se ... então" para nos referirmos a acontecimentos que dependem de outros, na logica a ideia é muito semelhante.

Retornando aos primeiros problemas do capítulo, relembramos um dos problemas descritos: % lembrar de add os exemplos na introdução %
\begin{center}
\textbf{Se Ana viajar para o Chile, comprará pesos chilenos}

\textbf{Se a família real não tivesse vindo ao Brasil, então o território se desintegraria}
\end{center}

Apesar das duas sentenças terem a mesma estrutura "Se... então", podemos perceber que as duas tem suas diferenças. Em particular, chamamos a segunda proposição de implicação contrafactual, pois ela afirma como o mundo possivelmente seria, caso a realidade fosse diferentes do que ela realmente é. Esse assunto é discutido por filósofos há seculos e Spinoza e Saul Kripke são nomes de destaque nesses estudos. Entretanto, a lógica matemática se debruça mais especialmente na primeira sentença.

Dessa forma, tomando a primeira sentença como objeto de estudo, como podemos valorar essa implicação?
Para começar a analisar a valoração dessa implicação pensemos em A correspondendo o evento "Ana viaja para o Chile" e B ao evento "Ana compra pesos chilenos". Temos, então, dois casos e uma tabela verdade correpondente:

\begin{center}

Caso 1: Ana viaja para o Chile 

Caso 2: Ana não viaja para o Chile

\end{center}

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline

\textbf{A} & \textbf{B} & \textbf{A $\to$ B} \\ \hline
V          & V          & V                  \\ \hline
V          & F          & F                  \\ \hline
F          & V          & V                  \\ \hline
F          & F          & V                  \\ \hline

\end{tabular}
\end{table}

No primeiro caso, Ana viaja para o Chile e A é verdadeiro. Dessa forma, para a implicação ser verdadeira, B precisa ver também verdadeiro.

No segundo caso, Ana não viaja para o Chile e A é falso.
Dessa forma, nada podemos dizer sobre o evento B e qualquer valor atribuído a ele torna a implicação verdadeira. A esse tipo de afirmação, chamamos de \textbf{verdadeira por vacuidade}.\\

Vamos agora analisar a implicação contrária:
\begin{center}

\textbf{Se Ana comprar pesos chilenos, viajará para o Chile}

\end{center}
Ainda analisando o evento A como "Ana viaja para o Chile" e B como "Ana compra pesos chilenos", temos a seguinte tabela verdade:

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline

\textbf{B} & \textbf{A} & \textbf{B $\to$ A} \\ \hline
V          & V          & V                  \\ \hline
V          & F          & F                  \\ \hline
F          & V          & V                  \\ \hline
F          & F          & V                  \\ \hline

\end{tabular}
\end{table}

A partir da comparação das duas tabelas podemos perceber que a segunda e terceira linhas evidenciam que, apesar de A e B terem o mesmo valor nas duas tabelas, a implicação tem uma valoração diferente. Ou seja, A $\to$ B $\neq$ B $\to$ A. Esse resultado condiz com a nossa intuição pois uma vez que embora saibamos que se Ana viaja para o Chile, comprará pesos chilenos, uma vez que Ana comprou pesos chilenos, não podemos afirmar com certeza que ela viajará para o Chile. Quem sabe Ana seja uma colecionadora de moedas internacionais?\\

Além disso, a implicação é protagonista da regra chamada "regra da exclusão da implicação" ou \textit{Modus Ponens}("A maneira que afirma afirmando" ), ou seja:

\begin{center}

Se Ana viajar para o Chile, comprará pesos chilenos

Ana viajou para o Chile

Ana comprou pesos chilenos

\end{center}

Escrito em dedução natural como:

\begin{prooftree}
    \AxiomC{$A \rightarrow B$}
    \AxiomC{A}
    \BinaryInfC{B}
\end{prooftree}

E com seu correspondente no Lean, sendo:

\vspace{5mm}
\begin{lstlisting} 

section
variable h1 : A → B
variable h2 : A

example : B := h1 h2
end

\end{lstlisting}
\vspace{5mm}

Por outro lado, existe também a "regra de inclusão da implicação". Uma vez que temos uma variável A e conseguimos derivar uma variável B, dizemos que \textbf{A implica em B}. E utilizamos em nossas árvores de dedução natural de tal forma:

\begin{prooftree}
    \AxiomC{$A$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$B$}
    \UnaryInfC{$A \rightarrow B$}
\end{prooftree}

Enquanto no Lean:

\vspace{5mm}
\begin{lstlisting} 

example : A → B :=
assume h : A,
show B, from sorry

\end{lstlisting}
\vspace{5mm}

\subsection{Se e somente se}

Já vimos anteriormente que $A \rightarrow B \neq B \rightarrow A$. Entretanto, em muitos casos na Matemática conseguimos chegar na igualdade dessas duas implicações e precisamos expressar a estrutura da linguagem falada "Se, e somente se". Dessa forma, faz-se uso do símbolo chamado de "bi-implicação" e representado por $\iff$ \\
Poderíamos também utilizar a formalização $A \rightarrow B \land B \rightarrow A$, mas por questões ligadas a praticidade da abreviação, é preferível o uso do novo símbolo apresentado.\\
Para entender melhor a interpretação dessa regra, usaremos o exemplo abaixo:

\begin{center}
    \textbf{Ana viajará para o Chile se, e somente se, comprar pesos chilenos}
\end{center}

Novamente construiremos a bi-implicação tratando o evento A como sendo "Ana viaja ao Chile" e B "Ana compra pesos chilenos". A tabela verdade então será:

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline

\textbf{A} & \textbf{B} & \textbf{A $\iff$ B} \\ \hline
V          & V          & V                  \\ \hline
V          & F          & F                  \\ \hline
F          & V          & F                  \\ \hline
F          & F          & V                  \\ \hline

\end{tabular}
\end{table}

Para melhor visualização dos resultados, vamos também mostrar uma tabela verdade que utiliza a definição da bi-implicação com o "e":

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline

\textbf{A} & \textbf{B} & \textbf{A $\iff$ B}& \textbf{B $\iff$ A} & \textbf{(B $\iff$ A) $\land$ (A $\iff$ B)} \\ \hline
V          & V          & V                  & V                   & V\\ \hline
V          & F          & F                  & V                   & F\\ \hline
F          & V          & F                  & V                   & F\\ \hline
F          & F          & V                  & V                   & V\\ \hline

\end{tabular}
\end{table}

Dessa forma, temos os casos:
\begin{center}

Caso 1: Ana viaja para o Chile 

Caso 2: Ana não viaja para o Chile

Caso 3: Ana compra pesos chilenos

Caso 4: Ana não compra pesos chilenos

\end{center}
Assim, com essa sentença sabemos que o caso 1 acontece se, e somente se o caso 3 acontece, e o caso 2 acontece se, e somente se o caso 4 também acontece.\\
Em dedução natural a regra da inclusão bi-implicação evidencia a necessidade de possuirmos duas implicações verdadeiras. Escrevemos a regra como:

\begin{prooftree}
    \AxiomC{$A$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$B$}
    \AxiomC{$B$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$A$}
    \BinaryInfC{$A \iff B$}
\end{prooftree}

No lean, temos o comando "iff.intro" que introduz o símbolo dado a verdade das duas implicações:
\vspace{5mm}
\begin{lstlisting} 

example : A ↔ B :=
iff.intro
  (assume h : A,
    show B, from sorry)
  (assume h : B,
    show A, from sorry)

\end{lstlisting}
\vspace{5mm}

Enquanto para a exclusão, a regra em dedução natural é muito semelhante a regra da exclusão da implicação:

\begin{prooftree}
    \AxiomC{$A \iff B$}
    \AxiomC{$A$}
    \BinaryInfC{$B$}
\end{prooftree}
\begin{prooftree}
    \AxiomC{$A \iff B$}
    \AxiomC{$B$}
    \BinaryInfC{$A$}
\end{prooftree}

E seu correspondente no lean é feito pelos comandos de eliminação a direita e a esquerda:

\vspace{5mm}
\begin{lstlisting} 

section
  variable h1 : A ↔ B
  variable h2 : A

  example : B := iff.elim_left h1 h2
end

section
  variable h1 : A ↔ B
  variable h2 : B

  example : A := iff.elim_right h1 h2
end

\end{lstlisting}
\vspace{5mm}


\subsection{Conjunção}
A regra da conjunção se refere ao uso ``e'' na linguagem informal, de forma que juntamos duas informações. Podemos ter frases como:
\begin{center}
\textbf{Santiago é a capital do Chile e o deserto do Atacama está localizado no Chile.}
\end{center}

Ao mesmo tempo, podemos utilizar o ``e'' para conectar duas informações que nem mesmo possuem relação entre si. Por exemplo, podemos dizer que:
\begin{center}
\textbf{Santiago é a capital do Chile e Bolsonaro é o presidente do Brasil.}
\end{center}
Quando utilizamos o ``e'', representado pelo símbolo $\land$ na lógica, o que de fato importa é estarmos unindo duas informações que são verdadeiras. Isso fica claro na tabela verdade abaixo, na qual é possível ver que quando $A$ ou quando $B$ são falsos, $A\land B$ é falso:

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{A} & \textbf{B} & \textbf{A $\land$ B} \\ \hline
V          & V          & V                  \\ \hline
V          & F          & F                  \\ \hline
F          & V          & F                  \\ \hline
F          & F          & F                  \\ \hline
\end{tabular}
\end{table}

Dessa forma, na dedução natural, podemos introduzir um ``e'', quando temos $A$ e também temos $B$. Assim, se $A$ e $B$ forem verdadeiros, $A \land B$ também vai ser. 

 \begin{prooftree}
     \AxiomC{A}
     \AxiomC{B}
     \BinaryInfC{$A \land B$}
\end{prooftree}

No Lean, representamos essa operação pela função $and.intro$, conforme o exemplo abaixo:
\vspace{5mm}
\begin{lstlisting} 
variables A B : Prop

example (h1 : A) (h2 : B) : A ∧ B :=
and.intro h1 h2
\end{lstlisting}
\vspace{5mm}

Seguindo esse raciocínio, é possível observar que sempre que temos $A \land B$, teremos $A$ e $B$ separadamente. Essa é a operação chamada de exclusão do ``e''.

Para excluir o $B$ de, por exemplo, $A \land B$, temos a chamada exclusão pela esquerda, conforme descrita abaixo:

 \begin{prooftree}
     \AxiomC{$A \land B$}
     \UnaryInfC{A}
\end{prooftree}

No Lean, essa operação pode ser feita utilizando a função $and.left$, conforme o código a seguir: 
\vspace{5mm}
\begin{lstlisting} 
variables A B : Prop

example (h1 : A ∧ B): A :=
and.left h1
\end{lstlisting}
\vspace{5mm}

Alternativamente, é possível realizar a mesma operação da seguinte forma:
\vspace{5mm}
\begin{lstlisting} 
variables A B : Prop

example (h1 : A ∧ B): A :=
h1.left
\end{lstlisting}
\vspace{5mm}
Para excluir o $A$, temos a chamada exclusão pela direita:

 \begin{prooftree}
     \AxiomC{$A \land B$}
     \UnaryInfC{B}
\end{prooftree}

No Lean, essa operação é realizada utilizando a função $and.right$, de maneira semelhante ao que foi descrito anteriormente para o $and.left$. 

\subsection{Disjunção}

A regra da disjunção se refere ao uso do ``ou''. Na linguagem informal, podemos utilizá-lo para expressar situações excludentes, como da seguinte forma:
\begin{center}
\textbf{Alexandre vai viajar para o Atacama ou Alexandre vai viajar para Santiago.}\\
\end{center}
Nesse caso, é possível que uma pessoa compreenda que somente uma das duas situações vai ocorrer, ou seja, que Alexandre somente vai para um dos dois lugares no Chile. Contudo, quando utilizamos o  ``ou'' na lógica, representado pelo símbolo $\lor$, também estamos levando em consideração situações nas quais ambas as proposições são verdadeiras. Dessa forma, conforme indicado na tabela verdade a seguir, a sentença formada pelo ``ou'' será verdadeira quando somente $A$ for verdadeiro, quando somente $B$ for verdadeiro ou quando ambos forem verdadeiros. 

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{A} & \textbf{B} & \textbf{A $\lor$ B} \\ \hline
V          & V          & V                 \\ \hline
V          & F          & V                 \\ \hline
F          & V          & V                 \\ \hline
F          & F          & F                 \\ \hline
\end{tabular}
\end{table}

Não só o ``ou'' formará uma sentença verdadeira quando uma ou ambas as situações forem verdadeiras, como também quando ambas as situações forem verdadeiras, mas não possuírem nenhuma relação entre si. Por exemplo, a seguinte sentença é verdadeira: 
\begin{center}
\textbf{Santiago é a capital do Chile ou Bolsonaro é o presidente do Brasil.}\\
\end{center}

É verdadeiro que Santiago é a capital do Chile e que Bolsonaro é o presidente do Brasil. Logo, toda a sentença é verdadeira, apesar de não soar de forma natural na linguagem informal.

Na dedução natural, como o ``ou'' é verdadeiro mesmo que somente um de seus elementos seja verdadeiro, introduzimos o $\lor$ tendo somente $A$ ou somente $B$. Logo, pode-se formar $A \lor B$ da seguinte forma:
\begin{prooftree}
     \AxiomC{A}
     \UnaryInfC{$A \lor B$}
\end{prooftree}

%adicionar explicacao de como o lean entende que o B ficara do lado direito do ou

No Lean, essa operação de introdução do ``ou'' é realizada utilizando a função $or.inl$. Essa função indica que queremos adicionar o $A$ do lado esquerdo do $\lor$ (por isso, ``or include left''). Dessa forma, teremos o seguinte código: 
\begin{lstlisting} 
variables A B : Prop

example (h1 : A): A ∨ B :=
or.inl h1
\end{lstlisting} 

Alternativamente, é possível realizar a introdução do $\lor$ a partir do $B$:
\begin{prooftree}
     \AxiomC{B}
     \UnaryInfC{$A \lor B$}
\end{prooftree}

Nesse caso, como o $B$ está sendo adicionado à direita do $\lor$ utilizamos a função $or.inr$ no Lean (ou seja,  ``or include right''). 

\begin{lstlisting} 
variables A B : Prop

example (h1 : B): A ∨ B :=
or.inr h1
\end{lstlisting} 

Para excluir o ``ou'' de $A \lor B$ é preciso estruturar uma árvore de dedução natural de forma que $A$ e $B$ resultem em um mesmo resultado $C$. Chegando nesse $C$, é possível substituir o $A \lor B$ pelo C. A seguinte árvore de dedução natural demonstra essa estrutura:

\begin{prooftree}
    \AxiomC{$A \lor B$}
    \AxiomC{$A$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$C$}
    \AxiomC{$B$}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$C$}
    \TrinaryInfC{$C$}
\end{prooftree}
     
No Lean, para excluir o ``ou'', utiliza-se a função $or.elim$. Ao lado do $or.elim$ é necessário inserir a hipótese contendo o ``ou'',  que deseja-se eliminar. Em seguida, deve-se abrir dois parênteses. Esses dois parênteses serão equivalentes às duas colunas contendo, respectivamente, $A$ e $B$ na árvore de dedução natural acima. Dessa forma, um parênteses começa com o $assume$ de $A$ e o outro com o$assume$ de $B$. O objetivo é que a partir deles chegue-se à hipótese C.  O código abaixo mostra a estrutura de como ficaria uma operação de eliminação do ``ou''(o ``sorry'' nas provas abaixo representa a etapa em que se prova que a partir de $A$ é possível chegar em $C$) :

\begin{lstlisting}
variables A B C D : Prop

example (h1: A ∨ B): C :=
or.elim h1
(assume h2: A, sorry)
(assume h2: B, sorry)
\end{lstlisting}

Como exemplo mais concreto, sem o uso do ``sorry'', é possível observar a prova abaixo, na qual utiliza-se as hipóteses $A \rightarrow C$ e $B \rightarrow C$ para se chegar à C a partir de $A$ e $B$:

\begin{lstlisting} 
variables A B C D : Prop

example (h1 : A → C) (h2 : B → C) (h3: A ∨ B): C :=
or.elim h3
(assume h4: A,
show C, from h1 h4)
(assume h4: B, 
show C, from h2 h4)
\end{lstlisting} 


\subsection{Negação}
%Incluir um exemplo de algum "quebra-cabeça"
A negação de $A$ é  representada  em  símbolos por $\neg A $. 
Mostrar que $\neg A $ ocorre, em termos lógicos, é o mesmo que mostrar que $A $ leva a uma contradição. Em dedução natural, temos uma prova que tem a seguinte árvore, na qual $\bot$ é o símbolo para falso, contradição ou absurdo:
\begin{prooftree}
    \AxiomC{A}
    \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$\bot$}
    \UnaryInfC{$\neg A$}
\end{prooftree}

Esta é uma outra forma de raciocínio hipotético, similar a utilizada em "se ... então" . Começamos supondo $A$. Em seguida, continuamos a prova aplicando as regras  já apresentadas, representadas pelos três pontinhos na árvore de dedução natural, até chegarmos a uma contradição.

A pergunta a se fazer em seguida é: de que forma uma contradição aparece numa prova, ou seja, como a encontramos? Suponha, por exemplo, que ao construir uma prova temos uma hipótese $A$ que nos leva a concluir que uma outra hipotése $B$ ocorre ao mesmo tempo que $\neg B$ também ocorre, no entanto se temos $B$ e  $ \neg B $, então temos uma contradição.
Em dedução natural, representamos essa ideia por:

\begin{prooftree}
    \AxiomC{$\neg B$}
    \AxiomC{B}
    \BinaryInfC{$\bot$}
\end{prooftree}

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{A} & \textbf{$\neg A$}  \\ \hline
V          & F                            \\ \hline
F          & V                            \\ \hline
\end{tabular}
\end{table}

A tabela verdade reforça o fato de que é ímpossível que uma proposição e sua negação sejam ambas verdadeiras ao mesmo tempo.

Ao utilizarmos o Lean, as regras de inferência de eliminação e introdução da negação podem ser obtidas atráves dos comandos a seguir: 

\begin{lstlisting} 
variables p q : Prop
-- show false, from ...

example (h1 : P → Q) (h2 : ¬Q) : ¬P :=
assume hp : P,
    show false, from h2 (h1 hp)
\end{lstlisting} 

Note que a hipotése que contém a negação vem primeiro após o \verb|from| e \textit{Q} é resultado do uso da regra de eliminação da implicação, além disso o símbolo $\neg Q$ é escrito como \verb| \not Q|. Na biblioteca padrão do Lean, $ \neg P$ é na verdade uma abreviação de $ P \rightarrow false $, ou seja, o fato de que $P$ implica uma contradição.

Uma vez apresentado o símbolo para \textit{falso}, a seguir apresentamos o símbolo para \textit{verdadeiro}. No entanto,  \textit{verdadeiro} ou \textit{true} não possui regra de eliminação, apenas a regra de introdução:

\begin{prooftree}
    \AxiomC{}
    \UnaryInfC{$\top $}
\end{prooftree}

%Citar mais alguma info sobre o símbolo true?

\subsection{Prova por contradição}

Existe um estilo de fazer matemático conhecido como "matemática construtivista" que nega a equivalência de $\neg \neg A$ e $ A$. Uma prova de que algo é verdadeiro deveria fornecer evidências explícitas de que uma declaração é falsa, em vez de evidências de que ela não pode ser falsa.

Antes de utilizar a prova por absurdo precisamos abrir o modo clássico do Lean.

\section{Exemplos adicionais de Dedução Natural}

Nesta seção serão apresentados exemplos adicionais de provas de dedução natural e seus equivalentes no Lean. Também será explicado como construir essas árvores do zero, partindo somente do  que se quer provar.  


\textbf{1. Prova de A $\rightarrow$ C a partir de A $\rightarrow$ B e B $\rightarrow$ C:}

\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
                               \AxiomC{$A \rightarrow B$}
                   \BinaryInfC{B}
                                        \AxiomC{$B \rightarrow C$}
                                 \BinaryInfC{C}
                                 \RightLabel{\scriptsize(1)}
                                 \UnaryInfC{$A \rightarrow C$}
\end{prooftree}

Como construir essa prova? Primeiro, começamos pelo que se quer provar: $A \rightarrow C$. Podemos escrever isso na última linha, já que é onde queremos chegar. Como a prova é de uma implicação, sabemos que na linha logo acima dessa vamos chegar no $C$:
\begin{prooftree}
\AxiomC{C}
\UnaryInfC{$A \rightarrow C $}
\end{prooftree}

Agora podemos considerar as hipóteses. Como a prova é de $A\rightarrow C$, vamos utilizar o $A$ em algum momento na árvore. Além disso, pelo enunciado, sabemos que vamos também utilizar o  $A \rightarrow B$ e $B \rightarrow C$. Então teremos uma estrutura razoavelmente parecida com essa: 

\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
        \noLine
        \UnaryInfC{$\vdots$}
    \AxiomC{$A \rightarrow B$}
        \noLine
        \UnaryInfC{$\vdots$}
    \AxiomC{$B \rightarrow C$}
        \noLine
        \UnaryInfC{$\vdots$}
    \TrinaryInfC{$C$}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \rightarrow C $}
\end{prooftree}
     
A partir disso, é possível observar com mais facilidade quais regras de dedução natural podem ser aplicadas ao problema. No caso, observamos que temos $A$ e $A\rightarrow B$. Logo, é possível obter $B$. 

\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
    \AxiomC{$A \rightarrow B$}
    \BinaryInfC{$B$}
    \AxiomC{$B \rightarrow C$}
        \noLine
        \UnaryInfC{$\vdots$}
    \BinaryInfC{$C$}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \rightarrow C $}
\end{prooftree}
     
Por fim, obtemos $C$ a partir de $B$ e de $B \rightarrow C$, formando a árvore apresentada de início. 

No Lean, essa prova poderia ser feita da seguinte forma: 
\begin{lstlisting}
variables A B C: Prop
example (h1: A → B) (h2: B → C): A → C :=
assume h3: A,
have h4: B, from h1 h3,
h2 h4
\end{lstlisting}

Para escrevê-la, adicionamos ao lado de $example$ as hipóteses que não vão ser descartadas. No caso, como o enunciado diz que vamos utilizar $A\rightarrow B$ e $B\rightarrow C$ para realizar a prova, adicionamos os dois depois de $example$. Em seguida, adicionamos $:$ e o que queremos provar, seguido de $:=$. 

Para o teor da prova, devemos considerar que a ordem no qual escrevemos no Lean importa. Logo, devemos seguir razoavelmente a ordem da árvore de dedução natural. Na árvore desse problema, é possível observar que a prova começa com o $A$ (do $A \rightarrow C$). Como essa é uma hipótese que vai ser descartada, escrevemos ela com o $assume$. Como a hipótese $A \rightarrow B$ já está escrita no $example$, podemos utilizá-la para encontrar $B$. Nesse caso, utilizamos o $have$ para atribuir o nome de uma variável ao $B$. Isso permite uma organização maior e evita que, em provas longas, tenha que se repetir muitas vezes como encontrar uma determinada variável. Contudo, não é necessário utilizar o $have$. Nesse caso, por exemplo, somente utilizamos o $B$ uma vez, para aplicá-lo ao $B \rightarrow C$. Logo, poderíamos ter escrito a prova da seguinte forma:

\begin{lstlisting}
variables A B C: Prop
example (h1: A → B) (h2: B → C): A → C :=
assume h3: A,
h2 (h1 h3)
\end{lstlisting}

A prova acima também pode ser intuitivamente pensada como (A $\rightarrow$ B) $\land$ (B $\rightarrow$ C) $\rightarrow$ (A $\rightarrow$ C). Nesse caso, teria-se a seguinte árvore:

\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
               \AxiomC{}
               \RightLabel{\scriptsize(2)}
               \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C)$}
               \UnaryInfC{$A \rightarrow B$}
        \BinaryInfC{B}
                                           \AxiomC{}
                                           \RightLabel{\scriptsize(2)}
                                           \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C)$}
                                           \UnaryInfC{$B \rightarrow C$}
                          \BinaryInfC{$C$}
                          \RightLabel{\scriptsize(1)}
                          \UnaryInfC{$A \rightarrow C$}
                          \RightLabel{\scriptsize(2)}
                          \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C) \rightarrow (A \rightarrow C)$}
\end{prooftree}

Para construir a árvore acima, poderia-se adotar essa estratégia: primeiro, começamos pelo que se quer provar ($(A \rightarrow B) \land (B \rightarrow C) \rightarrow (A \rightarrow C)$). Como vamos chegar em $A \rightarrow C$, podemos colocá-lo logo acima do que queremos provar. Ainda assim, continuamos com uma implicação, então podemos inserir o $C$ antes do $A \rightarrow C$. 

Como hipótese, teremos o o $A$ (de $A \rightarrow C$) e o $(A \rightarrow B) \land (B \rightarrow C)$ (vindo do resultado final: $(A \rightarrow B) \land (B \rightarrow C) \rightarrow (A \rightarrow C)$). Assim, teremos uma estrutura dessa forma: 
\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{A}
        \noLine
        \UnaryInfC{$\vdots$}
    \AxiomC{}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C)$}
        \noLine
        \UnaryInfC{$\vdots$}
    \BinaryInfC{$C$}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \rightarrow C$}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$(A \rightarrow B) \land (B \rightarrow C) \rightarrow (A \rightarrow C)$}
\end{prooftree}
     
Como sabemos que queremos chegar em um $C$, podemos utilizar o $B \rightarrow C$ para isso ($B \rightarrow C$ pode ser obtido a partir da operação de exclusão do $\land$ na hipótese de número 2) . Contudo, é necessário ter $B$ para realizar essa operação. O $B$ pode ser obtido a partir do $A$ e do $A \rightarrow B$. Logo, é possível construir a árvore. 

No Lean essa prova poderia ser feita da seguinte forma: 
\begin{lstlisting}
variables A B C: Prop
example: ((A → B) ∧ (B → C)) → (A → C) :=
assume h1: (A → B) ∧ (B → C),
assume h2: A,
have h3: B, from (and.left h1) h2,
(and.right h1) h3
\end{lstlisting}

Nas duas árvores de deduçao natural acima, podemos observar a utilização de números em determinadas hipóteses. Utilizamos esses para evidenciar onde descartamos as hipóteses marcadas. 

\textbf{2. Prova de $Q\land S$ a partir de $(P\land Q)\land R$ e $S \land T$:}

\begin{prooftree}
    \AxiomC{$(P \land Q) \land S$}
    \UnaryInfC{$P \land Q$}
    \UnaryInfC{Q}
                                      \AxiomC{$S \land T$}
                                      \UnaryInfC{S}
                      \BinaryInfC{$Q \land S$}
\end{prooftree}
Nesse caso, não descartamos nenhuma hipótese pois assumimos $(P\land Q)\land R$ e $S \land T$ como verdade e apenas derivamos a prova.

Para construir essa prova, partimos também de onde queremos chegar: $Q \land S$. Para formar um $\land$, precisamos de $Q$ e de $S$ separadamente. Logo, podemos escrevê-los acima do $Q \land S$. Pelo enunciado, sabemos que vamos usar como hipótese: $(P\land Q)\land R$ e $S \land T$. Assim, teremos a seguinte estrutura: 

\begin{prooftree}
    \AxiomC{$(P \land Q) \land S$}
     \noLine
    \UnaryInfC{$\vdots$}
     \noLine
    \UnaryInfC{$Q$}
    \AxiomC{$S \land T$}
     \noLine
    \UnaryInfC{$\vdots$}
     \noLine
    \UnaryInfC{S}
    \BinaryInfC{$Q \land S$}
\end{prooftree}

É possível obter o $S$ a partir de qualquer uma das hipóteses. O $Q$ só é possível obter a partir de $(P \land Q) \land S$. Logo, a partir de uma série de operações de exclusão do $\land$, constrói-se a parte restante da prova. 

No Lean, essa prova poderia ser feita da seguinte forma: 

\begin{lstlisting}
variables P Q R S T: Prop
example (h1: (P ∧ Q) ∧ R) (h2: S ∧ T): Q ∧ S :=
have h3: Q, from and.right (and.left h1),
have h4: S, from and.left h2,
and.intro h3 h4
\end{lstlisting}

\textbf{3. Prova de $(A \rightarrow (B \rightarrow C)) \rightarrow (A \land B \rightarrow C)$} :
\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$A \rightarrow (B \rightarrow C)$}
                                               \AxiomC{}
                                               \RightLabel{\scriptsize(1)}
                                               \UnaryInfC{$A \land B$}
                                               \UnaryInfC{A}
                        \BinaryInfC{$B \rightarrow C$}
                                                                          \AxiomC{}
                                                                          \RightLabel{\scriptsize(1)}
                                                                          \UnaryInfC{$A \land B$}
                                                                          \UnaryInfC{B}
                                                      \BinaryInfC{C}
                                                      \RightLabel{\scriptsize(1)}
                                                      \UnaryInfC{$A \land B \rightarrow C$}
                                                      \RightLabel{\scriptsize(2)}
                                                      \UnaryInfC{$(A \rightarrow (B \rightarrow C)) \rightarrow (A \land B \rightarrow C) $}
\end{prooftree}

%essa prova é bem parecida com as outras, preciso explicar?

\textbf{4. Prova de $A \land B \iff B \land A$:}
\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \land B$}
    \UnaryInfC{B}
                              \AxiomC{}
                              \RightLabel{\scriptsize(1)}
                              \UnaryInfC{$A\land B$}
                              \UnaryInfC{A}
             \BinaryInfC{$B \land A$}
                                                         \AxiomC{}
                                                         \RightLabel{\scriptsize(2)}
                                                         \UnaryInfC{$B \land A $}
                                                         \UnaryInfC{A}
                                                                                    \AxiomC{}
                                                                                    \RightLabel{\scriptsize(2)}
                                                                                    \UnaryInfC{$B \land A$}
                                                                                    \UnaryInfC{B}
                                                                     \BinaryInfC{$A \land B$}
                                                                     \RightLabel{\scriptsize(1,2)}
                                      \BinaryInfC{$A \land B \iff B \land A$}
\end{prooftree}

Para construir essa prova, partimos do $A \land B \iff B \land A$ ao final da prova. Para obtê-lo, precisamos partir de $B \land A$ e chegar no $A \land B$ e também partir de  $A \land B$ e chegar em $B \land A$. Sabendo que chegaremos nos dois, podemos escrevê-los na linha acima de  $A \land B \iff B \land A$. Sabendo que partiremos também dos dois, podemos escrevê-los como hipóteses. Teremos, assim, uma estrutura como essa: 
\begin{prooftree}
    \AxiomC{}
    \RightLabel{\scriptsize(1)}
    \UnaryInfC{$A \land B$}
     \noLine
    \UnaryInfC{$\vdots$}
     \noLine
    \UnaryInfC{$B \land A$}
    \AxiomC{}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$B \land A$}
     \noLine
    \UnaryInfC{$\vdots$}
     \noLine
    \UnaryInfC{$A \land B$}
    \RightLabel{\scriptsize(1,2)}
    \BinaryInfC{$A \land B \iff B \land A$}
\end{prooftree}

Para formar $A \land B$ e $B \land A$ precisamos de $A$ e $B$ separadamente. Estes podem ser obtidos a partir das hipóteses. Logo, repetindo as hipóteses e realizando a exclusão do $\land$, formamos a árvore final.

No Lean, essa prova poderia ser construída da seguinte forma:
\begin{lstlisting}
variables A B C: Prop
example: A ∧ B ↔ B ∧ A :=
iff.intro 
    (assume h1: A ∧ B,
    and.intro (and.right h1) (and.left h1))
    (assume h3: B ∧ A,
    and.intro (and.right h3) (and.left h3))

\end{lstlisting}

\textbf{5. Prova de $A \land (B \lor C) \rightarrow (A \land B) \lor (A \land C)$:}

\begin{prooftree}

\AxiomC{}                   
\RightLabel{\scriptsize(2)} 
\UnaryInfC{$A \land (B \lor C)$}                
\UnaryInfC{$B \lor C$}

\AxiomC{}
\RightLabel{\scriptsize(2)} 
\UnaryInfC{$A \land (B \lor C)$}
\UnaryInfC{A}
\AxiomC{}
\RightLabel{\scriptsize(1)} 
\UnaryInfC{B}
\BinaryInfC{$A \land B$}
\UnaryInfC{$(A \land B) \lor (A \land C)$}

\AxiomC{}
\RightLabel{\scriptsize(2)} 
\UnaryInfC{$A \land (B \lor C)$}
\UnaryInfC{A}
\AxiomC{}
\RightLabel{\scriptsize(1)} 
\UnaryInfC{C}
\BinaryInfC{$A \land C$}
\UnaryInfC{$(A \land B ) \lor (A \land C)$}

            \RightLabel{\scriptsize(1)} 
            \TrinaryInfC{$ (A \land B) \lor (A \land C)$}
            \RightLabel{\scriptsize(2)} 
           \UnaryInfC{$A \land (B \lor C) \rightarrow (A \land B) \lor (A \land C)$}
\end{prooftree}

Para escrever essa prova, podemos partir, como nas outras, do objetivo final: $A \land (B \lor C) \rightarrow (A \land B) \lor (A \land C)$. Como estamos provando uma implicação, vamos chegar em $(A \land B) \lor (A \land C)$ na linha anterior. Observamos também que $A \land (B \lor C)$ será uma hipótese. Teremos, então, uma estrutura como essa:

\begin{prooftree}
 \AxiomC{}
\RightLabel{\scriptsize(2)} 
\UnaryInfC{$A \land (B \lor C)$}
     \noLine
    \UnaryInfC{$\vdots$}
    \noLine
    \UnaryInfC{$(A \land B) \lor (A \land C)$}
    \RightLabel{\scriptsize(2)}
    \UnaryInfC{$A \land (B \lor C) \rightarrow (A \land B) \lor (A \land C)$}
\end{prooftree}

Como proceder a partir dessa estrutura? Para formar o $(A \land B) \lor (A \land C)$ será necessário o $A \land B$ isoladamente ou o $A \land C$ (a partir de qualquer um dos dois é possível realizar a introdução do $\lor$ e assim chegar em $(A \land B) \lor (A \land C)$). Independente de qual dos dois serão utilizados, nota-se que, para formar o ``e'', será necessário: o $A$ e também o $B$ ou o $C$. O $A$ pode ser facilmente obtido  a partir da hipótese. Para obter $B$ ou $C$ isoladamente, será necessário realizar a exclusão do $B \lor C$ contido no ``e'' da hipótese. Nota-se que para realizar a exclusão do ``ou'', é necessário considerar $B$ e $C$ como hipótese. Assim, podemos formar tanto $A \land B$, quanto $A \land C$. Dessa forma, é possível chegar no resultado final descrito acima. 

No Lean, essa prova poderia ser construída da seguinte forma:
\begin{lstlisting}
variables A B C: Prop
example: (A ∧ (B ∨ C)) → ((A ∧ B) ∨ (A ∧ C)) :=
assume h1: A ∧ (B ∨ C),
have h2: B ∨ C, from and.right h1,
have h4: A, from and.left h1,
or.elim h2
    (assume h3: B, 
    or.inl (and.intro h4 h3))
    (assume h3: C,
    or.inr (and.intro h4 h3))
\end{lstlisting}

\textbf{6. Prova do Princípio da Casa dos Pombos (PHP-3):}
    O princípio da casa dos pombos afirma que se $n$ pombos devem ser postos em $m$ casas, e se $n > m$, então pelo menos uma casa irá conter mais de um pombo. Apesar desse princípio  generalizado ser muito amplo para ser provado por árvores dedutivas, conseguimos provar o caso de 3 pombos e 2 casas de pombo utilizando árvores dedutivas.
    %tentaremos por a árvore?%

No Lean, essa prova poderia ser construída da seguinte forma: 
\begin{lstlisting}
variables P11 P12 P21 P22 P31 P32 : Prop

example: ((P11 ∨ P12) ∧ (P21 ∨ P22)) ∧ (P31 ∨ P32) → (P22 ∧ P32) ∨ ((P11 ∧ P31) ∨ ((P12 ∧ P22) ∨ ((P11 ∧ P21) ∨ ((P12 ∧ P32) ∨ (P21 ∧ P31))))) :=

assume h: ((P11 ∨ P12) ∧ (P21 ∨ P22)) ∧ (P31 ∨ P32),
have ha: P11 ∨ P12, from and.left (and.left h),
or.elim ha
    (assume h1: P11, 
        have hb: P21 ∨ P22, from and.right (and.left h),
            or.elim hb
                (assume h2: P21, or.inr (or.inr (or.inr (or.inl (and.intro h1 h2)))))
                (assume h2: P22, 
                    have hc: P31 ∨ P32, from and.right h,
                        or.elim hc
                            (assume h3: P31, or.inr (or.inl (and.intro h1 h3)))
                            (assume h3: P32, or.inl (and.intro h2 h3))))
    (assume h1: P12, 
        have hb: P21 ∨ P22, from and.right (and.left h),
            or.elim hb
                (assume h2: P21, 
                    have hc: P31 ∨ P32, from and.right h,
                        or.elim hc
                            (assume h3: P31, or.inr (or.inr (or.inr (or.inr (or.inr (and.intro h2 h3))))))
                            (assume h3: P32, or.inr (or.inr (or.inr (or.inr (or.inl (and.intro h1 h3)))))))
                (assume h2: P22, or.inr (or.inr (or.inl (and.intro h1 h2)))))
\end{lstlisting}

\end{itemize}

%Exemplos adicionais que eu tenho em Lean (temos que decidir quais vamos colocar como exercício, quais como exemplo e quais vamos fazer a árvore de dedução natural -- acho que faltam árvores contendo negação e contradição):
\begin{lstlisting}
open classical
variables {A B C D E F P Q R : Prop}

example : A ∧ (A → B) → B :=
assume h: A ∧ (A → B),
have h2: A → B, from and.right h,
have h3: A, from and.left h,
h2 h3

---
example : A → ¬ (¬ A ∧ B) :=
assume h1: A,
assume h2: ¬ A ∧ B,
have h3: ¬A, from and.left h2,
false.elim (h3 h1)

---
example : ¬ (A ∧ B) → (A → ¬ B) :=
assume h1: ¬ (A ∧ B),
assume h2: A,
assume h3: B,
have h4: A ∧ B, from and.intro h2 h3,
false.elim (h1 h4)

---
example (h1 : A ∨ B) (h2 : A → C) (h3 : B → D) : C ∨ D :=
or.elim h1
    (assume h: A, show C ∨ D, from or.inl (h2 h))
    (assume h: B, show C ∨ D, from or.inr (h3 h))

---
example (h : ¬ A ∧ ¬ B) : ¬ (A ∨ B) :=
assume h1: A ∨ B,
or.elim h1
    (assume h2: A, false.elim ((and.left h) h2))
    (assume h2: B, false.elim((and.right h) h2))

---
example : ¬ (A ↔ ¬ A) :=
assume h1: A ↔ ¬ A,
have h2: ¬ A, from
	assume h4: A, 
	have h2: ¬  A, from iff.elim_left h1 h4,
	false.elim (h2 h4),
have h3: ¬ ¬ A, from 
	assume h4: ¬ A,
	have h3: A, from iff.elim_right h1 h4,
	false.elim (h4 h3),
false.elim (h3 h2)

---
example (h1 : A ∨ ¬ A) (h2: ¬ A → false) : A := 
or.elim h1
    (assume h: A, 
    show A, from h)
    (assume h: ¬ A, 
    show A, from false.elim (h2 h))

---

example (h: ¬ A ∨ ¬ B): ¬ (A ∧ B) :=
assume hab: A ∧ B,
show false, from
    or.elim h
    (assume h2: ¬ A ,
    show false, from h2 (hab.left))
    (assume h3: ¬ B,
    show false, from h3 (hab.right))

---

lemma stepA (h₁ : ¬ (A ∧ B)) (h₂ : A) : ¬ A ∨ ¬ B :=
have ¬ B, from (assume hk:B,
show false, from h₁ (and.intro h₂ hk)),
show ¬ A ∨ ¬ B, from or.inr this

lemma stepB (h₁ : ¬ (A ∧ B)) (h₂ : ¬ (¬ A ∨ ¬ B)) : false :=
have ¬ A, from
  assume : A,
  have ¬ A ∨ ¬ B, from stepA h₁ ‹A›,
  show false, from h₂ this,
show false, from (h₂ (or.inl this) )

theorem stepC (h : ¬ (A ∧ B)) : ¬ A ∨ ¬ B :=
by_contradiction
  (assume h' : ¬ (¬ A ∨ ¬ B),
    show false, from stepB h h')


---

example (h5: ¬P →(Q ∨ R)) (h6:¬ Q) (h7:¬ R) :P:=
by_contradiction(
assume hp: ¬ P,
have hqr: Q ∨ R , from h5 hp,
show false, from
    or.elim hqr
    (assume hi: Q,
    show false, from h6 hi)
    (assume hii: R,
    show false, from h7 hii))

---

example (h8:A → B):¬ A ∨ B:=
or.elim(em A)
    (assume he: A,
    show (¬ A ∨ B),from or.inr (h8 he) )
    (assume hi: ¬ A,
    show(¬ A ∨ B),from or.inl hi)

---

example :A → (A ∧ B) ∨ (A ∧ ¬ B):=
assume h9: A,
show (A ∧ B) ∨  (A ∧ ¬ B), from
or.elim(em B)
    (assume hr:B,
    show (A ∧ B) ∨  (A ∧ ¬ B), from or.inl(and.intro h9 hr) )
    (assume hw: ¬ B,
    show (A ∧ B) ∨  (A ∧ ¬ B), from or.inr(and.intro h9 hw))

---

example: ((A ∨ B) ∧ (C ∨ D)) ∧ (E ∨ F) →  (((((((((A ∧ E) ∧ C) ∨ ((F ∧ B) ∧ D)) ∨ ((A ∧ F) ∧ C)) ∨ ((A ∧ E) ∧ D)) ∨ ((A ∧ F) ∧ D)) ∨ ((B ∧ E) ∧ C)) ∨ ((B ∧ F) ∧ C)) ∨ ((B ∧ E) ∧ D)) :=
assume h: ((A ∨ B) ∧ (C ∨ D)) ∧ (E ∨ F),
have ha: A ∨ B, from and.left (and.left h),
or.elim ha
    (assume h1: A, have hb: C ∨ D, from and.right (and.left h),
    or.elim hb
        (assume h2: C, have hc: E ∨ F, from and.right h,
        or.elim hc
            (assume h3: E, or.inl (or.inl (or.inl (or.inl (or.inl (or.inl (or.inl (and.intro (and.intro h1 h3) h2))))))))
            (assume h3: F, or.inl (or.inl (or.inl (or.inl (or.inl (or.inr (and.intro (and.intro h1 h3) h2))))))))
        (assume h2: D, have hc: E ∨ F, from and.right h,
        or.elim hc
            (assume h3: E, or.inl (or.inl (or.inl (or.inl (or.inr (and.intro (and.intro h1 h3) h2))))))
            (assume h3: F, or.inl (or.inl (or.inl (or.inr (and.intro (and.intro h1 h3) h2)))))))
    (assume h1: B, have hb: C ∨ D, from and.right (and.left h),
    or.elim hb
        (assume h2: C, have hc: E ∨ F, from and.right h,
        or.elim hc
            (assume h3: E, or.inl (or.inl (or.inr (and.intro (and.intro h1 h3) h2))))
            (assume h3: F, or.inl (or.inr (and.intro (and.intro h1 h3) h2))))
        (assume h2: D, have hc: E ∨ F, from and.right h,
        or.elim hc
            (assume h3: E, or.inr (and.intro (and.intro h1 h3) h2))
            (assume h3: F, or.inl (or.inl (or.inl (or.inl (or.inl (or.inl (or.inr (and.intro (and.intro h3 h1) h2))))))))))


---

lemma step1 (h₁ : ¬ (A ∧ B)) (h₂ : A) : ¬ A ∨ ¬ B :=
have ¬ B, from (assume hk:B,
show false, from h₁ (and.intro h₂ hk)),
show ¬ A ∨ ¬ B, from or.inr this

lemma step2 (h₁ : ¬ (A ∧ B)) (h₂ : ¬ (¬ A ∨ ¬ B)) : false :=
have ¬ A, from
  assume : A,
  have ¬ A ∨ ¬ B, from step1 h₁ ‹A›,
  show false, from h₂ this,
show false, from (h₂ (or.inl this) )

theorem step3 (h : ¬ (A ∧ B)) : ¬ A ∨ ¬ B :=
by_contradiction
  (assume h' : ¬ (¬ A ∨ ¬ B),
    show false, from step2 h h')

example (hl : ¬ B → ¬ A) : A → B :=
assume h10: A, show B,from
by_contradiction(
    assume hnb: ¬ B,
    show false, from (hl hnb) h10)

---
example (hp : A → B) : ¬ A ∨ B :=
show ¬ A ∨ B, from
or.elim (em A)
    (assume ha1: A,
    show ¬A ∨ B, from or.inr (hp ha1) )
    (assume ha2: ¬ A,
    show ¬A ∨ B, from or.inl ha2)
\end{lstlisting}

\begin{lstlisting}

---vestidos:
variables AA AB AP MA MB MP CA CB CP : Prop 
variable h1: AA ∨ (AB ∨ AP)
variable h2: MA ∨ (MB ∨ MP)
variable h3: CA ∨ CB ∨ CP
variable h4: AA → AB
variable h5: CA → ¬ AB
variable h6: AB → MB
variable h7: CB → ¬ MB
variable h8: AP → CB
variable h9: CP → ¬ CB
variable h10: ¬ AB
variable h11: (AA → (¬ AB ∧ ¬ AP)) ∧ (AB → (¬ AA ∧ ¬ AP)) ∧ (AP → (¬ AB ∧ ¬ AA))
variable h12: (MA → (¬ MB ∧ ¬ MP)) ∧ (MB → (¬ MA ∧ ¬ MP)) ∧ (MP → (¬ MB ∧ ¬ MA))
variable h13: (CA → (¬ CB ∧ ¬ CP)) ∧ (CB → (¬ CA ∧ ¬ CP)) ∧ (CP → (¬ CB ∧ ¬ CA))
variable h14: (AA → (¬ MA ∧ ¬ CA)) ∧ (AB → (¬ MB ∧ ¬ CB)) ∧ (AP → (¬ MP ∧ ¬ CP))
variable h15: (MA → (¬ AA ∧ ¬ CA)) ∧ ((MB → (¬ AB ∧ ¬ CB)) ∧ (MP → (¬ AP ∧ ¬ CP)))
variable h16: (CA → (¬ AA ∧ ¬ MA)) ∧ (CB → (¬ AB ∧ ¬ MB)) ∧ (CP → (¬ AP ∧ ¬ MP))

example: ((AP ∧ CB) ∧ MA) :=

have h17: AP, from 
or.elim h1
    (assume h18: AA, false.elim (h10 (h4 h18)))
    (assume h18: AB ∨ AP,
        or.elim h18
            (assume h19: AB, false.elim (h10 h19))
            (assume h19: AP, h19)),

have h20: CB, from 
(h8 h17),

have h24: (AP ∧ CB), from and.intro h17 h20,

have h21: MA, from 
or.elim h2
(assume h22: MA, h22)
(assume h22: MB ∨ MP,
or.elim h22
(assume h23: MB, false.elim ((and.right ((and.left (and.right h15)) h23)) (and.right h24)))
(assume h23: MP, false.elim ((and.left ((and.right (and.right h15)) h23)) (and.left h24)))),

and.intro h24 h21
\end{lstlisting}

\begin{lstlisting}

--hamiltonian path:

open classical 
variables {x11 x12 x13 x14 x21 x22 x23 x24 x31 x32 x33 x34 x41 x42 x43 x44 : Prop}

/-     grafo:               caminho:
     x1 ---- x2        x11 ∧ x22 ∧ x33 ∧ x44         
     |        |       e, naturalmente ¬xij para
     x4------x3       qualquer outro par i,j          
-/


--- REGRA 1 E 3 ---
lemma rule_1and3 (h1: x11 ∧ x22 ∧ x33 ∧ x44):
(((x11 ∨ x21 ∨ x31 ∨ x41)∧ 
(x44 ∨ x14 ∨ x24 ∨ x34))∧
(x33 ∨ x13 ∨ x23 ∨ x43))∧
(x22 ∨ x12 ∨ x32 ∨ x42)
  :=
  show 
  (((x11 ∨ x21 ∨ x31 ∨ x41)∧ 
  (x44 ∨ x14 ∨ x24 ∨ x34))∧
  (x33 ∨ x13 ∨ x23 ∨ x43))∧
  (x22 ∨ x12 ∨ x32 ∨ x42), 
  from and.intro 
        (and.intro 
            (and.intro 
                (or.inl h1.left)
                (or.inl h1.right.right.right))
            (or.inl h1.right.right.left))
        (or.inl h1.right.left)

--- REGRA 2 ---

--- para o nó 1 ---
lemma rule_2_node1 (h2: x11 ∧ ¬x21 ∧ ¬x31 ∧ ¬x41 ∧ x22 ∧ x33 ∧ x44):
  (((((¬ x11 ∨ ¬  x21)∧
      (¬ x11 ∨ ¬  x31))∧ 
      (¬ x11 ∨ ¬  x41))∧ 
      (¬ x21 ∨ ¬  x31))∧ 
      (¬ x21 ∨ ¬  x41))∧ 
      (¬ x31 ∨ ¬  x41)
  :=
  show(((((¬ x11 ∨ ¬  x21)∧
      (¬ x11 ∨ ¬  x31))∧ 
      (¬ x11 ∨ ¬  x41))∧ 
      (¬ x21 ∨ ¬  x31))∧ 
      (¬ x21 ∨ ¬  x41))∧ 
      (¬ x31 ∨ ¬  x41),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inr h2.right.left ) 
                              ( or.inr h2.right.right.left ))
                            (or.inr h2.right.right.right.left))
                          (or.inl h2.right.left))
                    (or.inl h2.right.left))
          (or.inl h2.right.right.left)

--- para o nó 2 ---
lemma rule_2_node2 (h2: x11 ∧ ¬x12 ∧ ¬x32 ∧ ¬x42 ∧ x22 ∧ x33 ∧ x44):
  (((((¬ x12 ∨ ¬  x22)∧
      (¬ x12 ∨ ¬  x32))∧ 
      (¬ x12 ∨ ¬  x42))∧ 
      (¬ x22 ∨ ¬  x32))∧ 
      (¬ x22 ∨ ¬  x42))∧ 
      (¬ x32 ∨ ¬  x42):=
  show
    (((((¬ x12 ∨ ¬  x22)∧
      (¬ x12 ∨ ¬  x32))∧ 
      (¬ x12 ∨ ¬  x42))∧ 
      (¬ x22 ∨ ¬  x32))∧ 
      (¬ x22 ∨ ¬  x42))∧ 
      (¬ x32 ∨ ¬  x42),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inl h2.right.left ) 
                              ( or.inl h2.right.left ))
                            (or.inl h2.right.left))
                          (or.inr h2.right.right.left))
                    (or.inr h2.right.right.right.left))
          (or.inl h2.right.right.left)

--- para o nó 3 ---
lemma rule_2_node3 (h2: x11 ∧ ¬x13 ∧ ¬x43 ∧ ¬x23 ∧ x22 ∧ x33 ∧ x44):
  (((((¬ x13 ∨ ¬  x23)∧
      (¬ x13 ∨ ¬  x33))∧ 
      (¬ x13 ∨ ¬  x43))∧ 
      (¬ x23 ∨ ¬  x33))∧ 
      (¬ x23 ∨ ¬  x43))∧ 
      (¬ x33 ∨ ¬  x43):=
  show
   (((((¬ x13 ∨ ¬  x23)∧
      (¬ x13 ∨ ¬  x33))∧ 
      (¬ x13 ∨ ¬  x43))∧ 
      (¬ x23 ∨ ¬  x33))∧ 
      (¬ x23 ∨ ¬  x43))∧ 
      (¬ x33 ∨ ¬  x43),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inl h2.right.left ) 
                              ( or.inl h2.right.left ))
                            (or.inl h2.right.left))
                          (or.inl h2.right.right.right.left))
                    (or.inl h2.right.right.right.left))
          (or.inr h2.right.right.left)

--- para o nó 4 ---
lemma rule_2_node4 (h2: x11 ∧ ¬x14 ∧ ¬x34 ∧ ¬x24 ∧ x22 ∧ x33 ∧ x44):
  (((((¬ x14 ∨ ¬  x24)∧
      (¬ x14 ∨ ¬  x34))∧ 
      (¬ x14 ∨ ¬  x44))∧ 
      (¬ x24 ∨ ¬  x34))∧ 
      (¬ x24 ∨ ¬  x44))∧ 
      (¬ x34 ∨ ¬  x44):=
  show
   (((((¬ x14 ∨ ¬  x24)∧
      (¬ x14 ∨ ¬  x34))∧ 
      (¬ x14 ∨ ¬  x44))∧ 
      (¬ x24 ∨ ¬  x34))∧ 
      (¬ x24 ∨ ¬  x44))∧ 
      (¬ x34 ∨ ¬  x44),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inl h2.right.left ) 
                              ( or.inl h2.right.left ))
                            (or.inl h2.right.left))
                          (or.inl h2.right.right.right.left))
                    (or.inl h2.right.right.right.left))
          (or.inl h2.right.right.left)

--- REGRA 4 ---

--- para a posição 1 ---
lemma rule_4_node1 (h2: ¬x12 ∧ ¬x13 ∧ ¬x14 ∧ x11 ∧ x22 ∧ x33 ∧ x44):
  (((((¬ x11 ∨ ¬  x12)∧
      (¬ x11 ∨ ¬  x13))∧ 
      (¬ x11 ∨ ¬  x14))∧ 
      (¬ x12 ∨ ¬  x13))∧ 
      (¬ x12 ∨ ¬  x14))∧ 
      (¬ x13 ∨ ¬  x14):=
  show
   (((((¬ x11 ∨ ¬  x12)∧
      (¬ x11 ∨ ¬  x13))∧ 
      (¬ x11 ∨ ¬  x14))∧ 
      (¬ x12 ∨ ¬  x13))∧ 
      (¬ x12 ∨ ¬  x14))∧ 
      (¬ x13 ∨ ¬  x14),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inr h2.left ) 
                              ( or.inr h2.right.left ))
                            (or.inr h2.right.right.left))
                          (or.inl h2.left))
                    (or.inl h2.left))
          (or.inl h2.right.left)

--- para a posição 2 ---
lemma rule_4_node2 (h2: ¬x21 ∧ ¬x23 ∧ ¬x24 ∧ x11 ∧ x22 ∧ x33 ∧ x44):
  (((((¬ x21 ∨ ¬  x22)∧
      (¬ x21 ∨ ¬  x23))∧ 
      (¬ x21 ∨ ¬  x24))∧ 
      (¬ x22 ∨ ¬  x23))∧ 
      (¬ x22 ∨ ¬  x24))∧ 
      (¬ x23 ∨ ¬  x24):=
  show
  (((((¬ x21 ∨ ¬  x22)∧
      (¬ x21 ∨ ¬  x23))∧ 
      (¬ x21 ∨ ¬  x24))∧ 
      (¬ x22 ∨ ¬  x23))∧ 
      (¬ x22 ∨ ¬  x24))∧ 
      (¬ x23 ∨ ¬  x24),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inl h2.left ) 
                              ( or.inl h2.left ))
                            (or.inl h2.left))
                          (or.inr h2.right.left))
                    (or.inr h2.right.right.left))
          (or.inl h2.right.left)

--- para a posição 3 ---
lemma rule_4_node3 (h2: ¬x31 ∧ ¬x32 ∧ ¬x34 ∧ x11 ∧ x22  ∧ x33 ∧ x44):
  (((((¬ x31 ∨ ¬  x32)∧
      (¬ x31 ∨ ¬  x33))∧ 
      (¬ x31 ∨ ¬  x34))∧ 
      (¬ x32 ∨ ¬  x33))∧ 
      (¬ x32 ∨ ¬  x34))∧ 
      (¬ x33 ∨ ¬  x34):=
  show
  (((((¬ x31 ∨ ¬  x32)∧
      (¬ x31 ∨ ¬  x33))∧ 
      (¬ x31 ∨ ¬  x34))∧ 
      (¬ x32 ∨ ¬  x33))∧ 
      (¬ x32 ∨ ¬  x34))∧ 
      (¬ x33 ∨ ¬  x34),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inl h2.left ) 
                              ( or.inl h2.left))
                            (or.inl h2.left))
                          (or.inl h2.right.left))
                    (or.inl h2.right.left))
          (or.inr h2.right.right.left)

--- para a posição 4 ---
lemma rule_4_node4 (h2: ¬x41 ∧ ¬x42 ∧ ¬x43 ∧  x11 ∧ x22  ∧ x33 ∧ x44):
  (((((¬ x41 ∨ ¬  x42)∧
      (¬ x41 ∨ ¬  x43))∧ 
      (¬ x41 ∨ ¬  x44))∧ 
      (¬ x42 ∨ ¬  x43))∧ 
      (¬ x42 ∨ ¬  x44))∧ 
      (¬ x43 ∨ ¬  x44):=
  show
  (((((¬ x41 ∨ ¬  x42)∧
      (¬ x41 ∨ ¬  x43))∧ 
      (¬ x41 ∨ ¬  x44))∧ 
      (¬ x42 ∨ ¬  x43))∧ 
      (¬ x42 ∨ ¬  x44))∧ 
      (¬ x43 ∨ ¬  x44),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inl h2.left ) 
                              ( or.inl h2.left))
                            (or.inl h2.left))
                          (or.inl h2.right.left))
                    (or.inl h2.right.left))
          (or.inl h2.right.right.left)

--- REGRA 5 ---

--- para os nós 1 e 3 ---
lemma rule_5_edge13 (h2: ¬x23 ∧ ¬x21 ∧ ¬x43 ∧ ¬x41 ∧  x11 ∧ x22  ∧ x33 ∧ x44):
  (((((¬ x11 ∨ ¬  x23)∧
      (¬ x21 ∨ ¬  x33))∧ 
      (¬ x31 ∨ ¬  x43))∧ 
      (¬ x13 ∨ ¬  x21))∧ 
      (¬ x23 ∨ ¬  x31))∧ 
      (¬ x33 ∨ ¬  x41):=
  show
  (((((¬ x11 ∨ ¬  x23)∧
      (¬ x21 ∨ ¬  x33))∧ 
      (¬ x31 ∨ ¬  x43))∧ 
      (¬ x13 ∨ ¬  x21))∧ 
      (¬ x23 ∨ ¬  x31))∧ 
      (¬ x33 ∨ ¬  x41),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inr h2.left ) 
                              ( or.inl h2.right.left))
                            (or.inr h2.right.right.left))
                          (or.inr h2.right.left))
                    (or.inl h2.left))
          (or.inr h2.right.right.right.left)

--- para os nós 3 e 4 ---
lemma rule_5_edge24 (h2: ¬x12 ∧ ¬x24 ∧ ¬x34 ∧ ¬x32 ∧  x11 ∧ x22  ∧ x33 ∧ x44):
  (((((¬ x12 ∨ ¬  x24)∧
      (¬ x22 ∨ ¬  x34))∧ 
      (¬ x32 ∨ ¬  x44))∧ 
      (¬ x14 ∨ ¬  x24))∧ 
      (¬ x24 ∨ ¬  x34))∧ 
      (¬ x34 ∨ ¬  x44):=
  show
  (((((¬ x12 ∨ ¬  x24)∧
      (¬ x22 ∨ ¬  x34))∧ 
      (¬ x32 ∨ ¬  x44))∧ 
      (¬ x14 ∨ ¬  x24))∧ 
      (¬ x24 ∨ ¬  x34))∧ 
      (¬ x34 ∨ ¬  x44),
  from and.intro
          (and.intro
                    (and.intro
                          (and.intro
                            (and.intro
                              ( or.inl h2.left ) 
                              ( or.inr h2.right.right.left))
                            (or.inl h2.right.right.right.left))
                          (or.inr h2.right.left))
                    (or.inl h2.right.left))
          (or.inl h2.right.right.left)
\end{lstlisting}

\section{Exercícios}
